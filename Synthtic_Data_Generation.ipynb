{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 20:15:20.477516: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 20:15:24.470861: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2023-08-08 20:15:24.471093: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2023-08-08 20:15:24.476314: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2023-08-08 20:15:24.885176: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 2 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Input, Dense, BatchNormalization, Conv2D, Conv2DTranspose, ReLU, LeakyReLU, Flatten, MaxPooling2D, Dropout, Reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1')\n",
      "DEVICES AVAILABLE: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 20:15:26.658788: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-08 20:15:26.662516: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon RX 6700S)\n",
      "2023-08-08 20:15:26.778223: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 1 (AMD Radeon(TM) Graphics)\n",
      "2023-08-08 20:15:26.867037: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-08 20:15:26.867090: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 1, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-08-08 20:15:26.867131: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2023-08-08 20:15:26.867171: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 13659 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2023-08-08 20:15:26.867448: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2023-08-08 20:15:26.867482: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:1 with 7156 MB memory) -> physical PluggableDevice (device: 1, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print('DEVICES AVAILABLE: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BUFFER_SIZE = 64000\n",
    "BATCH_SIZE = 32*strategy.num_replicas_in_sync\n",
    "batch_size = BATCH_SIZE\n",
    "EPOCHS = 1000\n",
    "latent_dim = 128\n",
    "input_size = [256*2, 256*2, 3]\n",
    "image_size = (256*2, 256*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = './data/archive/chest_xray/chest_xray/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3875 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "dataset= datagen.flow_from_directory(\n",
    "    os.path.join(image_directory, 'train'),   \n",
    "    classes=['PNEUMONIA'],   \n",
    "    target_size=image_size,        \n",
    "    batch_size=BATCH_SIZE,      \n",
    "    class_mode='binary',        \n",
    "    shuffle=True                 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_model():\n",
    "    #in case you get OOM error, change the filter size, set it to a smaller value, 28 for example\n",
    "    model = Sequential([\n",
    "        Input(shape = (latent_dim,)),\n",
    "        Dense(8*8*256),\n",
    "        Reshape((8, 8, 256)),\n",
    "        Conv2DTranspose(128*2, kernel_size = 4, strides = 2, padding = 'same'), \n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(128*3, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(128*3, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(128*4, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(128*5, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2DTranspose(128*6, kernel_size=4, strides=2, padding='same'),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Conv2D(3, kernel_size =4, padding = 'same', activation = 'sigmoid')\n",
    "    ],\n",
    "        name = \"generator\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discriminator Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disc_model():\n",
    "    model = Sequential([\n",
    "        Input(shape = input_size),\n",
    "        Conv2D(256, kernel_size = 4, strides= 2, padding = 'same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling2D(strides = 2),\n",
    "        Conv2D(256*2, kernel_size=4, strides=2, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling2D(strides=2),\n",
    "        Conv2D(256*3, kernel_size=4, strides=2, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling2D(strides=2),\n",
    "        Conv2D(256*4, kernel_size=4, strides=2, padding='same'),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        MaxPooling2D(strides=2),\n",
    "        \n",
    "        Flatten(),\n",
    "        Dense(256*4),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation = 'sigmoid')\n",
    "    ], \n",
    "        name = \"discriminator\"\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    }
   ],
   "source": [
    "with strategy.scope(): \n",
    "    generator = gen_model()\n",
    "    discriminator = disc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 16384)             2113536   \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_transpose (Conv2DTra  (None, 16, 16, 256)      1048832   \n",
      " nspose)                                                         \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_1 (Conv2DT  (None, 32, 32, 384)      1573248   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 32, 32, 384)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_2 (Conv2DT  (None, 64, 64, 384)      2359680   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 64, 64, 384)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_3 (Conv2DT  (None, 128, 128, 512)    3146240   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 128, 128, 512)     0         \n",
      "                                                                 \n",
      " conv2d_transpose_4 (Conv2DT  (None, 256, 256, 640)    5243520   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 256, 256, 640)     0         \n",
      "                                                                 \n",
      " conv2d_transpose_5 (Conv2DT  (None, 512, 512, 768)    7865088   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 512, 512, 768)     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 512, 512, 3)       36867     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 23,387,011\n",
      "Trainable params: 23,387,011\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_1 (Conv2D)           (None, 256, 256, 256)     12544     \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 256, 256, 256)    1024      \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 256, 256, 256)     0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 128, 128, 256)    0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 64, 64, 512)       2097664   \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 64, 64, 512)      2048      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 64, 64, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 32, 32, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 16, 16, 768)       6292224   \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 16, 16, 768)      3072      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 16, 16, 768)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 8, 8, 768)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 4, 4, 1024)        12583936  \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 4, 4, 1024)       4096      \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 2, 2, 1024)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              4195328   \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 1024)              0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 1025      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 25,192,961\n",
      "Trainable params: 25,187,841\n",
      "Non-trainable params: 5,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_loader(generator):\n",
    "    for images, labels in generator:\n",
    "        yield images, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN with Custom Traning Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gan(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super().__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "    \n",
    "    def compile(self, disc_opt, gen_opt, loss_function):\n",
    "        super().compile()\n",
    "        self.disc_opt = disc_opt\n",
    "        self.gen_opt = gen_opt\n",
    "        self.loss_function = loss_function\n",
    "        self.disc_loss_metric = tf.keras.metrics.Mean(name = \"disc_loss\")\n",
    "        self.gen_loss_metric = tf.keras.metrics.Mean(name = \"gen_loss\")\n",
    "        \n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.disc_loss_metric, self.gen_loss_metric]\n",
    "    \n",
    "    #custom training step\n",
    "    def train_step(self, data):  # Modify the function to accept labels separately\n",
    "        real_images, real_labels = data\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        # Fake image decoding\n",
    "        generated_images = self.generator(random_latent_vectors)\n",
    "\n",
    "        combined_images = tf.concat([generated_images, real_images], axis=0)\n",
    "\n",
    "        # Concatenate the real and fake labels\n",
    "        labels = tf.concat(\n",
    "            [tf.ones((batch_size, 1)), tf.zeros((batch_size, 1))], axis=0\n",
    "        )\n",
    "\n",
    "        \n",
    "        labels += 0.05*tf.random.uniform(tf.shape(labels))\n",
    "        \n",
    "        \n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(combined_images)\n",
    "            disc_loss = self.loss_function(labels, predictions)\n",
    "            \n",
    "        grads  = tape.gradient(disc_loss, self.discriminator.trainable_weights)\n",
    "        self.disc_opt.apply_gradients(\n",
    "            zip(grads, self.discriminator.trainable_weights)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        random_latent_vectors = tf.random.normal(shape = (batch_size,self.latent_dim))\n",
    "        \n",
    "        misleading_labels = tf.zeros((batch_size, 1))\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self.discriminator(self.generator(random_latent_vectors))\n",
    "            \n",
    "            gen_loss = self.loss_function(misleading_labels, predictions)\n",
    "            \n",
    "        grads = tape.gradient(gen_loss, self.generator.trainable_weights)\n",
    "        self.gen_opt.apply_gradients(zip(grads, self.generator.trainable_weights))\n",
    "        \n",
    "        self.disc_loss_metric.update_state(disc_loss)\n",
    "        self.gen_loss_metric.update_state(gen_loss)\n",
    "        return{\n",
    "            \"disc_loss\": self.disc_loss_metric.result(),\n",
    "            \"gen_loss\": self.gen_loss_metric.result()\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_images(current_epoch):\n",
    "    noise = tf.random.normal([2, latent_dim])\n",
    "    num_of_sample = 2\n",
    "    generated_images = generator(noise, training = False)\n",
    "    figure = plt.figure(figsize=(20,20))\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(2, 2,i+1)\n",
    "        plt.imshow(generated_images[i, :, :, 0, ], cmap = 'gray')\n",
    "        plt.title(f\"After epoch {current_epoch}\")        \n",
    "        plt.axis('off')\n",
    "    plt.savefig('After epochs{:04d}.png'.format(current_epoch))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Gan_Callback(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, num_images=2, latent_dim = 128):\n",
    "        self.num_images = num_images\n",
    "        self.latent_dim = latent_dim       \n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs =None):\n",
    "        latent_vectors = tf.random.normal(shape = (self.num_images, latent_dim))\n",
    "        generated_images = self.model.generator(latent_vectors)\n",
    "        generated_images *=255\n",
    "        generated_images.numpy()\n",
    "        figure = plt.figure(figsize=(10,10))\n",
    "        for i in range(generated_images.shape[0]):\n",
    "            plt.subplot(2, 2,i+1)\n",
    "            plt.imshow(generated_images[i, :, :, 0, ], cmap='gray')\n",
    "            plt.title(f\"After epoch {epoch+1}\")\n",
    "            plt.axis('off')\n",
    "        plt.savefig('After epochs{:04d}.png'.format(epoch+1))\n",
    "        plt.show()\n",
    "        if(epoch % 10 ==0):\n",
    "            self.model.generator.save('/Model/gen.h5')\n",
    "            self.model.discriminator.save('/Model/disc.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    gan = Gan(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "    gan.compile(\n",
    "        disc_opt=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5), \n",
    "        gen_opt=tf.keras.optimizers.Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "        loss_function=tf.keras.losses.BinaryCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using MirroredStrategy eagerly has significant overhead currently. We will be working on improving this in the future, but for now please wrap `call_for_each_replica` or `experimental_run` or `run` inside a tf.function to get the best performance.\n",
      "INFO:tensorflow:Error reported to Coordinator: Exception encountered when calling layer \"gan\" \"                 f\"(type Gan).\n",
      "\n",
      "Unimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n",
      "\n",
      "Call arguments received by layer \"gan\" \"                 f\"(type Gan):\n",
      "  • inputs=tf.Tensor(shape=(64, 512, 512, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/harsha/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/tensorflow/python/training/coordinator.py\", line 293, in stop_on_exception\n",
      "    yield\n",
      "  File \"/home/harsha/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/tensorflow/python/distribute/mirrored_run.py\", line 386, in run\n",
      "    self.main_result = self.main_fn(*self.main_args, **self.main_kwargs)\n",
      "  File \"/home/harsha/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 595, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/harsha/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/keras/engine/data_adapter.py\", line 878, in <lambda>\n",
      "    lambda x: model(x, training=False), args=(concrete_x,)\n",
      "  File \"/home/harsha/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"/home/harsha/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/keras/engine/training.py\", line 584, in call\n",
      "    raise NotImplementedError(\n",
      "NotImplementedError: Exception encountered when calling layer \"gan\" \"                 f\"(type Gan).\n",
      "\n",
      "Unimplemented `tf.keras.Model.call()`: if you intend to create a `Model` with the Functional API, please provide `inputs` and `outputs` arguments. Otherwise, subclass `Model` with an overridden `call()` method.\n",
      "\n",
      "Call arguments received by layer \"gan\" \"                 f\"(type Gan):\n",
      "  • inputs=tf.Tensor(shape=(64, 512, 512, 3), dtype=float32)\n",
      "  • training=False\n",
      "  • mask=None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-08 20:15:32.486430: W tensorflow/core/grappler/optimizers/data/auto_shard.cc:776] AUTO sharding policy will apply DATA sharding policy as it failed to apply FILE sharding policy because of the following reason: Did not find a shardable source, walked to a node which is not a dataset: name: \"FlatMapDataset/_2\"\n",
      "op: \"FlatMapDataset\"\n",
      "input: \"TensorDataset/_1\"\n",
      "attr {\n",
      "  key: \"Targuments\"\n",
      "  value {\n",
      "    list {\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"_cardinality\"\n",
      "  value {\n",
      "    i: -2\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"f\"\n",
      "  value {\n",
      "    func {\n",
      "      name: \"__inference_Dataset_flat_map_flat_map_fn_1379\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"metadata\"\n",
      "  value {\n",
      "    s: \"\\n\\020FlatMapDataset:1\"\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_shapes\"\n",
      "  value {\n",
      "    list {\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "      shape {\n",
      "        dim {\n",
      "          size: -1\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      "attr {\n",
      "  key: \"output_types\"\n",
      "  value {\n",
      "    list {\n",
      "      type: DT_FLOAT\n",
      "      type: DT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "experimental_type {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_DATASET\n",
      "    args {\n",
      "      type_id: TFT_PRODUCT\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "      args {\n",
      "        type_id: TFT_TENSOR\n",
      "        args {\n",
      "          type_id: TFT_FLOAT\n",
      "        }\n",
      "      }\n",
      "    }\n",
      "  }\n",
      "}\n",
      ". Consider either turning off auto-sharding or switching the auto_shard_policy to DATA to shard this dataset. You can do this by creating a new `tf.data.Options()` object then setting `options.experimental_distribute.auto_shard_policy = AutoShardPolicy.DATA` before applying the options object to the dataset via `dataset.with_options(options)`.\n",
      "2023-08-08 20:15:32.648126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 20:15:32.657429: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 20:15:32.674377: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-08-08 20:15:32.681656: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/harsha/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/keras/backend.py:5673: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 20 all-reduces with algorithm = nccl, num_packs = 1\n",
      "INFO:tensorflow:batch_all_reduce: 16 all-reduces with algorithm = nccl, num_packs = 1\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "No OpKernel was registered to support Op 'NcclAllReduce' used by {{node Adam/NcclAllReduce}} with these attrs: [reduction=\"sum\", shared_name=\"c2\", T=DT_FLOAT, num_devices=2]\nRegistered devices: [CPU, GPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[Adam/NcclAllReduce]] [Op:__inference_train_function_7857]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m gan\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m      2\u001b[0m     image_loader(dataset), \n\u001b[1;32m      3\u001b[0m     epochs\u001b[39m=\u001b[39;49mEPOCHS,\n\u001b[1;32m      4\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(dataset),  \n\u001b[1;32m      5\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[Gan_Callback(num_images\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m, latent_dim\u001b[39m=\u001b[39;49mlatent_dim)]\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/miniconda3/envs/tfdml_plugin/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: No OpKernel was registered to support Op 'NcclAllReduce' used by {{node Adam/NcclAllReduce}} with these attrs: [reduction=\"sum\", shared_name=\"c2\", T=DT_FLOAT, num_devices=2]\nRegistered devices: [CPU, GPU]\nRegistered kernels:\n  <no registered kernels>\n\n\t [[Adam/NcclAllReduce]] [Op:__inference_train_function_7857]"
     ]
    }
   ],
   "source": [
    "gan.fit(\n",
    "    image_loader(dataset), \n",
    "    epochs=EPOCHS,\n",
    "    steps_per_epoch=len(dataset),  \n",
    "    callbacks=[Gan_Callback(num_images=4, latent_dim=latent_dim)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfdml_plugin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
